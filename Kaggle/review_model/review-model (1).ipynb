{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.15","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10176026,"sourceType":"datasetVersion","datasetId":6285361},{"sourceId":10203913,"sourceType":"datasetVersion","datasetId":6305743},{"sourceId":10352371,"sourceType":"datasetVersion","datasetId":6410588},{"sourceId":10353766,"sourceType":"datasetVersion","datasetId":6411676},{"sourceId":198787,"sourceType":"modelInstanceVersion","modelInstanceId":169559,"modelId":191903}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader, Dataset\nfrom transformers import ElectraTokenizer, ElectraForSequenceClassification,  ElectraModel\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd \nfrom sklearn.preprocessing import LabelEncoder\nimport torch.nn as nn\nimport torch_xla.core.xla_model as xm\nfrom torch.optim import AdamW\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:24:46.892611Z","iopub.execute_input":"2025-01-09T05:24:46.892822Z","iopub.status.idle":"2025-01-09T05:25:20.733468Z","shell.execute_reply.started":"2025-01-09T05:24:46.892791Z","shell.execute_reply":"2025-01-09T05:25:20.732212Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n/usr/local/lib/python3.10/site-packages/torch_xla/__init__.py:202: UserWarning: `tensorflow` can conflict with `torch-xla`. Prefer `tensorflow-cpu` when using PyTorch/XLA. To silence this warning, `pip uninstall -y tensorflow && pip install tensorflow-cpu`. If you are in a notebook environment such as Colab or Kaggle, restart your notebook runtime afterwards.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"\nreview_train_df = pd.read_csv('/kaggle/input/review-train/review_sentiment.csv', index_col = 0)\n\n\npositive_reviews = review_train_df[review_train_df['sentiment'] == 1]\naugmented_reviews = positive_reviews.copy()\nreview_train_df = pd.concat([review_train_df, augmented_reviews], ignore_index=True)\n\nprint(\"데이터셋 크기:\", review_train_df.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:26:32.302071Z","iopub.execute_input":"2025-01-09T05:26:32.303082Z","iopub.status.idle":"2025-01-09T05:26:32.332288Z","shell.execute_reply.started":"2025-01-09T05:26:32.303037Z","shell.execute_reply":"2025-01-09T05:26:32.331374Z"}},"outputs":[{"name":"stdout","text":"데이터셋 크기: (1370, 2)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"sent_encoder = LabelEncoder()\n\nreview_train_df['sentiment'] = sent_encoder.fit_transform(review_train_df['sentiment'])\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    review_train_df['review'], \n    review_train_df['sentiment'], \n    test_size=0.2, \n    random_state=1, \n    stratify=review_train_df['sentiment']\n)\n\ntrain_texts = train_texts.reset_index(drop=True)\ntrain_labels = train_labels.reset_index(drop=True)\n\nval_texts = val_texts.reset_index(drop=True)\nval_labels = val_labels.reset_index(drop=True)\nreview_train_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:26:34.239666Z","iopub.execute_input":"2025-01-09T05:26:34.240727Z","iopub.status.idle":"2025-01-09T05:26:34.262295Z","shell.execute_reply.started":"2025-01-09T05:26:34.240690Z","shell.execute_reply":"2025-01-09T05:26:34.261486Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                                 review  sentiment\n0     물품 자체의 품질과 맛은 좋아서 정기적으로 주문하고 있습니다다만, 별점을 낮게 선택...          0\n1     서방아이디로 가입하고 긴 세월동안 스마일클럽 회원비따위가 뭐라고 수시로 터져서 오고...          0\n2     가격이 들쑥날쑥 처음부터 싸게 팔던가ㅡ가격을 일정하게 팔던가ㅡ가격이 지네들 맘대로네...          0\n3     비비고 곰탕 2박스를 화요일 오전에 신청하면 다음날 수요일에 배송 된다 하여 목요일...          0\n4     지금 장난 하나 딱 봐도 터져서 샌게 눈에 보이는데 그걸 테이프로 덕지덕지 감아서 ...          0\n...                                                 ...        ...\n1365                              이젠 자극적인 맛보다 순한 맛이 좋아요          1\n1366                                     순한맛 맛있어요 면발 쫄깃          1\n1367                                이마트배송 원하는시간에 최고입니다!          1\n1368                        진라면이 리뉴얼 됐다고하더니 기존것보다 맵네요..          0\n1369                                매운맛이 강해진 반면 좀 밍밍해요.          0\n\n[1370 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>물품 자체의 품질과 맛은 좋아서 정기적으로 주문하고 있습니다다만, 별점을 낮게 선택...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>서방아이디로 가입하고 긴 세월동안 스마일클럽 회원비따위가 뭐라고 수시로 터져서 오고...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>가격이 들쑥날쑥 처음부터 싸게 팔던가ㅡ가격을 일정하게 팔던가ㅡ가격이 지네들 맘대로네...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>비비고 곰탕 2박스를 화요일 오전에 신청하면 다음날 수요일에 배송 된다 하여 목요일...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>지금 장난 하나 딱 봐도 터져서 샌게 눈에 보이는데 그걸 테이프로 덕지덕지 감아서 ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1365</th>\n      <td>이젠 자극적인 맛보다 순한 맛이 좋아요</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1366</th>\n      <td>순한맛 맛있어요 면발 쫄깃</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1367</th>\n      <td>이마트배송 원하는시간에 최고입니다!</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1368</th>\n      <td>진라면이 리뉴얼 됐다고하더니 기존것보다 맵네요..</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1369</th>\n      <td>매운맛이 강해진 반면 좀 밍밍해요.</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1370 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"class SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length = 512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        inputs = self.tokenizer(\n            text,\n            padding = 'max_length',\n            truncation = True,\n            max_length = self.max_length,\n            return_tensors = 'pt'\n        )\n\n        input_ids = inputs['input_ids'].squeeze(0)\n        attention_mask = inputs['attention_mask'].squeeze(0)\n\n        return {'input_ids' : input_ids, 'attention_mask' : attention_mask, \n                'label' : torch.tensor(label).float() }\n\n\nclass LabelClassifier(nn.Module):\n\n    def __init__(self, model):\n        super(LabelClassifier, self).__init__()\n        self.model = model\n        self.sentiment_output = nn.Linear(model.config.hidden_size , 2)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask)\n        sentiment_logits = self.sentiment_output(outputs.last_hidden_state[:, 0, :])\n        sentiment_probs = torch.softmax(sentiment_logits, dim = -1)\n        return sentiment_probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:26:51.672830Z","iopub.execute_input":"2025-01-09T05:26:51.673259Z","iopub.status.idle":"2025-01-09T05:26:51.682173Z","shell.execute_reply.started":"2025-01-09T05:26:51.673226Z","shell.execute_reply":"2025-01-09T05:26:51.681254Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"tokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\npretrained_model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\nmodel = LabelClassifier(pretrained_model)\n\n\ntrain_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\nval_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size = 8 , shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True)\n\n\ndevice = xm.xla_device()\n\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr = 2e-5)\nloss_fn_sentiment = nn.CrossEntropyLoss()\nepochs = 3\nprint(f\"Using device: {device}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:26:53.678870Z","iopub.execute_input":"2025-01-09T05:26:53.679302Z","iopub.status.idle":"2025-01-09T05:27:03.342657Z","shell.execute_reply.started":"2025-01-09T05:26:53.679271Z","shell.execute_reply":"2025-01-09T05:27:03.341673Z"}},"outputs":[{"name":"stderr","text":"WARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1736400418.916073      13 common_lib.cc:818] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: ===\nlearning/45eac/tfrc/runtime/common_lib.cc:483\n","output_type":"stream"},{"name":"stdout","text":"Using device: xla:0\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].long().to(device)\n\n        optimizer.zero_grad()\n\n        sentiment_probs = model(input_ids = input_ids, attention_mask = attention_mask)\n\n        loss = loss_fn_sentiment(sentiment_probs, labels)\n        loss.backward()\n\n        xm.optimizer_step(optimizer)\n        xm.mark_step()\n\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_train_loss}\")\n\n\n    model.eval()\n    val_loss = 0\n    correct_labels = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            sentiment_probs = model(input_ids = input_ids, attention_mask = attention_mask)\n            loss_sentiment = loss_fn_sentiment(sentiment_probs, labels)\n\n            val_loss += loss_sentiment.item()\n            preds_labels = torch.argmax(sentiment_probs, dim = 1)\n            correct_labels += (preds_labels == labels).sum().item()\n\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy_labels = correct_labels / len(val_loader.dataset)\n    print(f\"Validation Loss: {avg_val_loss}, Accuracy (Sentiment): {accuracy_labels}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:28:15.549106Z","iopub.execute_input":"2025-01-09T05:28:15.549809Z","iopub.status.idle":"2025-01-09T05:34:28.075069Z","shell.execute_reply.started":"2025-01-09T05:28:15.549772Z","shell.execute_reply":"2025-01-09T05:34:28.073910Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3, Average Training Loss: 0.4573156855402202\nValidation Loss: 0.35879618184907097, Accuracy (Sentiment): 0.948905109489051\nEpoch 2/3, Average Training Loss: 0.34977419902808476\nValidation Loss: 0.35538491436413355, Accuracy (Sentiment): 0.9562043795620438\nEpoch 3/3, Average Training Loss: 0.342753036613882\nValidation Loss: 0.3478247616972242, Accuracy (Sentiment): 0.9598540145985401\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"#torch.save(model, '/kaggle/working/review_model_koelectra_complete.pt')\nmodel = torch.load('/kaggle/working/review_model_koelectra_complete.pt')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T04:58:14.369447Z","iopub.execute_input":"2025-01-08T04:58:14.370141Z","iopub.status.idle":"2025-01-08T04:58:14.424653Z","shell.execute_reply.started":"2025-01-08T04:58:14.370110Z","shell.execute_reply":"2025-01-08T04:58:14.423588Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\ntorch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:10:43.218129Z","iopub.execute_input":"2025-01-09T06:10:43.218573Z","iopub.status.idle":"2025-01-09T06:10:43.223485Z","shell.execute_reply.started":"2025-01-09T06:10:43.218539Z","shell.execute_reply":"2025-01-09T06:10:43.222377Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def calculate_metrics_with_threshold(model, val_loader, device, threshold=0.45):\n    model.eval()\n    tp, fn, tn, fp = 0, 0, 0, 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            # 데이터 로드\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            # 모델 예측\n            sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            # Threshold 적용\n            preds_labels = (sentiment_probs[:, 1] > threshold).long()  # Positive 클래스 확률 기준\n\n            # Recall 및 Specificity 계산\n            tp += ((preds_labels == 1) & (labels == 1)).sum().item()  # True Positives\n            fn += ((preds_labels == 0) & (labels == 1)).sum().item()  # False Negatives\n            tn += ((preds_labels == 0) & (labels == 0)).sum().item()  # True Negatives\n            fp += ((preds_labels == 1) & (labels == 0)).sum().item()  # False Positives\n\n    # Recall 계산\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n\n    # Specificity 계산\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    accuracy = (tn + tp) / (tn + tp + fp + fn)\n    return recall, specificity, accuracy\nfor threshold in [0.7, 0.5, 0.3]:\n    recall, specificity, accuracy = calculate_metrics_with_threshold(model, val_loader, device, threshold=threshold)\n    print(f\"Threshold: {threshold:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, \\\n    Accuracy : {accuracy:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:42:32.839580Z","iopub.execute_input":"2025-01-09T05:42:32.840117Z","iopub.status.idle":"2025-01-09T05:43:14.034680Z","shell.execute_reply.started":"2025-01-09T05:42:32.840079Z","shell.execute_reply":"2025-01-09T05:43:14.033447Z"}},"outputs":[{"name":"stdout","text":"Threshold: 0.7000, Recall: 0.9389, Specificity: 0.9860,     Accuracy : 0.9635\nThreshold: 0.5000, Recall: 0.9389, Specificity: 0.9790,     Accuracy : 0.9599\nThreshold: 0.3000, Recall: 0.9466, Specificity: 0.9790,     Accuracy : 0.9635\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"model = torch.load('/kaggle/input/review_sentiment_koelectra/pytorch/default/1/review_model_koelectra')\ntokenizer_path = '/kaggle/input/review_sentiment_koelectra/pytorch/default/1'\n\ntokenizer = ElectraTokenizer.from_pretrained(tokenizer_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T05:03:05.523639Z","iopub.execute_input":"2025-01-08T05:03:05.524040Z","iopub.status.idle":"2025-01-08T05:03:08.142265Z","shell.execute_reply.started":"2025-01-08T05:03:05.524005Z","shell.execute_reply":"2025-01-08T05:03:08.140579Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import BertTokenizer, BertModel\nfrom torch.utils.data import DataLoader\nimport torch\nimport torch.nn as nn\nfrom torch.optim import AdamW\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom torch.utils.data import Dataset\n\n# Label Encoding\nsent_encoder = LabelEncoder()\nreview_train_df['sentiment'] = sent_encoder.fit_transform(review_train_df['sentiment'])\n\n# Train-test split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    review_train_df['review'], \n    review_train_df['sentiment'], \n    test_size=0.2, \n    random_state=1, \n    stratify=review_train_df['sentiment']\n)\n\ntrain_texts = train_texts.reset_index(drop=True)\ntrain_labels = train_labels.reset_index(drop=True)\nval_texts = val_texts.reset_index(drop=True)\nval_labels = val_labels.reset_index(drop=True)\n\n# Dataset class\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        inputs = self.tokenizer(\n            text,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_length,\n            return_tensors='pt'\n        )\n\n        input_ids = inputs['input_ids'].squeeze(0)\n        attention_mask = inputs['attention_mask'].squeeze(0)\n\n        return {'input_ids': input_ids, 'attention_mask': attention_mask, \n                'label': torch.tensor(label).float()}\n\n# Model class\nclass LabelClassifier(nn.Module):\n    def __init__(self, model):\n        super(LabelClassifier, self).__init__()\n        self.model = model\n        self.sentiment_output = nn.Linear(model.config.hidden_size, 2)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        sentiment_logits = self.sentiment_output(outputs.last_hidden_state[:, 0, :])\n        sentiment_probs = torch.softmax(sentiment_logits, dim=-1)\n        return sentiment_probs\n\n# Define a function for training and evaluation\ndef train_and_evaluate(tokenizer_name, model_name):\n    print(f\"Training with {model_name}\")\n    tokenizer = BertTokenizer.from_pretrained(tokenizer_name)\n    pretrained_model = BertModel.from_pretrained(model_name)\n    model = LabelClassifier(pretrained_model)\n\n    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\n    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=2e-5)\n    loss_fn_sentiment = nn.CrossEntropyLoss()\n\n    epochs = 3\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for batch in train_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            optimizer.zero_grad()\n\n            sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            loss = loss_fn_sentiment(sentiment_probs, labels)\n            loss.backward()\n\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}\")\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        correct_labels = 0\n\n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['label'].long().to(device)\n\n                sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n                loss_sentiment = loss_fn_sentiment(sentiment_probs, labels)\n\n                val_loss += loss_sentiment.item()\n                preds_labels = torch.argmax(sentiment_probs, dim=1)\n                correct_labels += (preds_labels == labels).sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        accuracy_labels = correct_labels / len(val_loader.dataset)\n        print(f\"Validation Loss: {avg_val_loss}, Accuracy: {accuracy_labels}\")\n\n# Train with KoBERT\ntrain_and_evaluate('monologg/kobert', 'monologg/kobert')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T05:51:31.410006Z","iopub.execute_input":"2025-01-09T05:51:31.411141Z","iopub.status.idle":"2025-01-09T06:05:48.648557Z","shell.execute_reply.started":"2025-01-09T05:51:31.411066Z","shell.execute_reply":"2025-01-09T06:05:48.647376Z"}},"outputs":[{"name":"stdout","text":"Training with monologg/kobert\n","output_type":"stream"},{"name":"stderr","text":"The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \nThe tokenizer class you load from this checkpoint is 'KoBertTokenizer'. \nThe class this function is called from is 'BertTokenizer'.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/3, Average Training Loss: 0.6002283870738788\nValidation Loss: 0.6148579640047891, Accuracy: 0.6897810218978102\nEpoch 2/3, Average Training Loss: 0.5664916856445535\nValidation Loss: 0.6021664065974099, Accuracy: 0.718978102189781\nEpoch 3/3, Average Training Loss: 0.5576770423102553\nValidation Loss: 0.5804229634148734, Accuracy: 0.7153284671532847\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"\nreview_train_df = pd.read_csv('/kaggle/input/review-train/review_sentiment.csv', index_col = 0)\npositive_reviews = review_train_df[review_train_df['sentiment'] == 1]\naugmented_reviews = positive_reviews.copy()\nreview_train_df = pd.concat([review_train_df, augmented_reviews], ignore_index=True)\n\n\nsent_encoder = LabelEncoder()\n\nreview_train_df['sentiment'] = sent_encoder.fit_transform(review_train_df['sentiment'])\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    review_train_df['review'], \n    review_train_df['sentiment'], \n    test_size=0.2, \n    random_state=1, \n    stratify=review_train_df['sentiment']\n)\n\ntrain_texts = train_texts.reset_index(drop=True)\ntrain_labels = train_labels.reset_index(drop=True)\n\nval_texts = val_texts.reset_index(drop=True)\nval_labels = val_labels.reset_index(drop=True)# Label Encoding\nsent_encoder = LabelEncoder()\nreview_train_df['sentiment'] = sent_encoder.fit_transform(review_train_df['sentiment'])\n\n# Train-test split\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    review_train_df['review'], \n    review_train_df['sentiment'], \n    test_size=0.2, \n    random_state=1, \n    stratify=review_train_df['sentiment']\n)\n\ntrain_texts = train_texts.reset_index(drop=True)\ntrain_labels = train_labels.reset_index(drop=True)\nval_texts = val_texts.reset_index(drop=True)\nval_labels = val_labels.reset_index(drop=True)\n\n# Dataset class\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length=300):  # max_length 수정\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        inputs = self.tokenizer(\n            text,\n            padding='max_length',\n            truncation=True,\n            max_length=self.max_length,  # max_length 반영\n            return_tensors='pt'\n        )\n\n        input_ids = inputs['input_ids'].squeeze(0)\n        attention_mask = inputs['attention_mask'].squeeze(0)\n\n        return {'input_ids': input_ids, 'attention_mask': attention_mask, \n                'label': torch.tensor(label).float()}\n\n# Model class\nclass LabelClassifier(nn.Module):\n    def __init__(self, model):\n        super(LabelClassifier, self).__init__()\n        self.model = model\n        self.sentiment_output = nn.Linear(model.config.hidden_size, 2)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)\n        sentiment_logits = self.sentiment_output(outputs.last_hidden_state[:, 0, :])\n        sentiment_probs = torch.softmax(sentiment_logits, dim=-1)\n        return sentiment_probs\n\ndef train_and_evaluate(tokenizer_name, model_name, max_length):\n    print(f\"Training with {model_name}\")\n    tokenizer = BertTokenizer.from_pretrained(tokenizer_name)\n    pretrained_model = BertModel.from_pretrained(model_name)\n    model = LabelClassifier(pretrained_model)\n\n    train_dataset = SentimentDataset(train_texts, train_labels, tokenizer, max_length=max_length)\n    val_dataset = SentimentDataset(val_texts, val_labels, tokenizer, max_length=max_length)\n\n    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    optimizer = AdamW(model.parameters(), lr=2e-5)\n    loss_fn_sentiment = nn.CrossEntropyLoss()\n\n    epochs = 3\n\n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n\n        for batch in train_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            optimizer.zero_grad()\n\n            sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            loss = loss_fn_sentiment(sentiment_probs, labels)\n            loss.backward()\n\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        avg_train_loss = total_loss / len(train_loader)\n        print(f\"Epoch {epoch + 1}/{epochs}, Average Training Loss: {avg_train_loss}\")\n\n        # Validation\n        model.eval()\n        val_loss = 0\n        correct_labels = 0\n\n        with torch.no_grad():\n            for batch in val_loader:\n                input_ids = batch['input_ids'].to(device)\n                attention_mask = batch['attention_mask'].to(device)\n                labels = batch['label'].long().to(device)\n\n                sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n                loss_sentiment = loss_fn_sentiment(sentiment_probs, labels)\n\n                val_loss += loss_sentiment.item()\n                preds_labels = torch.argmax(sentiment_probs, dim=1)\n                correct_labels += (preds_labels == labels).sum().item()\n\n        avg_val_loss = val_loss / len(val_loader)\n        accuracy_labels = correct_labels / len(val_loader.dataset)\n        print(f\"Validation Loss: {avg_val_loss}, Accuracy: {accuracy_labels}\")\n\ntrain_and_evaluate('beomi/kcbert-base', 'beomi/kcbert-base', max_length=300)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:31:32.122714Z","iopub.execute_input":"2025-01-09T06:31:32.123118Z","iopub.status.idle":"2025-01-09T06:40:58.190998Z","shell.execute_reply.started":"2025-01-09T06:31:32.123079Z","shell.execute_reply":"2025-01-09T06:40:58.189859Z"}},"outputs":[{"name":"stdout","text":"Training with beomi/kcbert-base\nEpoch 1/3, Average Training Loss: 0.39658306502356316\nValidation Loss: 0.36725474280469556, Accuracy: 0.945679012345679\nEpoch 2/3, Average Training Loss: 0.34684646863655505\nValidation Loss: 0.3544377316446865, Accuracy: 0.9580246913580247\nEpoch 3/3, Average Training Loss: 0.3354789238845186\nValidation Loss: 0.4070997512808033, Accuracy: 0.9037037037037037\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"\nreview_train_df = pd.read_csv('/kaggle/input/review-train/review_sentiment.csv', index_col = 0)\n\n\npositive_reviews = review_train_df[review_train_df['sentiment'] == 1]\naugmented_reviews = positive_reviews.copy()\nreview_train_df = pd.concat([review_train_df, augmented_reviews], ignore_index=True)\n\nsent_encoder = LabelEncoder()\n\nreview_train_df['sentiment'] = sent_encoder.fit_transform(review_train_df['sentiment'])\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    review_train_df['review'], \n    review_train_df['sentiment'], \n    test_size=0.2, \n    random_state=1, \n    stratify=review_train_df['sentiment']\n)\n\ntrain_texts = train_texts.reset_index(drop=True)\ntrain_labels = train_labels.reset_index(drop=True)\n\nval_texts = val_texts.reset_index(drop=True)\nval_labels = val_labels.reset_index(drop=True)\nreview_train_df\n\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length = 512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        inputs = self.tokenizer(\n            text,\n            padding = 'max_length',\n            truncation = True,\n            max_length = self.max_length,\n            return_tensors = 'pt'\n        )\n\n        input_ids = inputs['input_ids'].squeeze(0)\n        attention_mask = inputs['attention_mask'].squeeze(0)\n\n        return {'input_ids' : input_ids, 'attention_mask' : attention_mask, \n                'label' : torch.tensor(label).float() }\n\n\nclass LabelClassifier(nn.Module):\n\n    def __init__(self, model):\n        super(LabelClassifier, self).__init__()\n        self.model = model\n        self.sentiment_output = nn.Linear(model.config.hidden_size , 2)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask)\n        sentiment_logits = self.sentiment_output(outputs.last_hidden_state[:, 0, :])\n        sentiment_probs = torch.softmax(sentiment_logits, dim = -1)\n        return sentiment_probs\n\n\ntokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\npretrained_model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\nmodel = LabelClassifier(pretrained_model)\n\n\ntrain_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\nval_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size = 8 , shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True)\n\n\ndevice = xm.xla_device()\n\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr = 2e-5)\nloss_fn_sentiment = nn.CrossEntropyLoss()\nepochs = 3\nprint(f\"Using device: {device}\")\n\n\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].long().to(device)\n\n        optimizer.zero_grad()\n\n        sentiment_probs = model(input_ids = input_ids, attention_mask = attention_mask)\n\n        loss = loss_fn_sentiment(sentiment_probs, labels)\n        loss.backward()\n\n        xm.optimizer_step(optimizer)\n        xm.mark_step()\n\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_train_loss}\")\n\n\n    model.eval()\n    val_loss = 0\n    correct_labels = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            sentiment_probs = model(input_ids = input_ids, attention_mask = attention_mask)\n            loss_sentiment = loss_fn_sentiment(sentiment_probs, labels)\n\n            val_loss += loss_sentiment.item()\n            preds_labels = torch.argmax(sentiment_probs, dim = 1)\n            correct_labels += (preds_labels == labels).sum().item()\n\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy_labels = correct_labels / len(val_loader.dataset)\n    print(f\"Validation Loss: {avg_val_loss}, Accuracy (Sentiment): {accuracy_labels}\")\n\n\ndef calculate_metrics_with_threshold(model, val_loader, device, threshold=0.45):\n    model.eval()\n    tp, fn, tn, fp = 0, 0, 0, 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            # 데이터 로드\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            # 모델 예측\n            sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            # Threshold 적용\n            preds_labels = (sentiment_probs[:, 1] > threshold).long()  # Positive 클래스 확률 기준\n\n            # Recall 및 Specificity 계산\n            tp += ((preds_labels == 1) & (labels == 1)).sum().item()  # True Positives\n            fn += ((preds_labels == 0) & (labels == 1)).sum().item()  # False Negatives\n            tn += ((preds_labels == 0) & (labels == 0)).sum().item()  # True Negatives\n            fp += ((preds_labels == 1) & (labels == 0)).sum().item()  # False Positives\n\n    # Recall 계산\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n\n    # Specificity 계산\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    accuracy = (tn + tp) / (tn + tp + fp + fn)\n    return recall, specificity, accuracy\nfor threshold in [0.7, 0.5, 0.3]:\n    recall, specificity, accuracy = calculate_metrics_with_threshold(model, val_loader, device, threshold=threshold)\n    print(f\"Threshold: {threshold:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, \\\n    Accuracy : {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:43:01.434384Z","iopub.execute_input":"2025-01-09T06:43:01.435542Z","iopub.status.idle":"2025-01-09T06:52:26.668524Z","shell.execute_reply.started":"2025-01-09T06:43:01.435494Z","shell.execute_reply":"2025-01-09T06:52:26.667519Z"}},"outputs":[{"name":"stdout","text":"Using device: xla:0\nEpoch 1/3, Average Training Loss: 0.40976559440490645\nValidation Loss: 0.34429242505746727, Accuracy (Sentiment): 0.9703703703703703\nEpoch 2/3, Average Training Loss: 0.3383751880065561\nValidation Loss: 0.34911946747817246, Accuracy (Sentiment): 0.9654320987654321\nEpoch 3/3, Average Training Loss: 0.35112667553530535\nValidation Loss: 0.3498621635577258, Accuracy (Sentiment): 0.9654320987654321\nThreshold: 0.7000, Recall: 0.9847, Specificity: 0.9301,     Accuracy : 0.9654\nThreshold: 0.5000, Recall: 0.9847, Specificity: 0.9301,     Accuracy : 0.9654\nThreshold: 0.3000, Recall: 0.9847, Specificity: 0.9231,     Accuracy : 0.9630\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"\nreview_train_df = pd.read_csv('/kaggle/input/review-train/review_sentiment.csv', index_col = 0)\n\nsent_encoder = LabelEncoder()\n\nreview_train_df['sentiment'] = sent_encoder.fit_transform(review_train_df['sentiment'])\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    review_train_df['review'], \n    review_train_df['sentiment'], \n    test_size=0.2, \n    random_state=1, \n    stratify=review_train_df['sentiment']\n)\n\ntrain_texts = train_texts.reset_index(drop=True)\ntrain_labels = train_labels.reset_index(drop=True)\n\nval_texts = val_texts.reset_index(drop=True)\nval_labels = val_labels.reset_index(drop=True)\nreview_train_df\n\nclass SentimentDataset(Dataset):\n    def __init__(self, texts, labels, tokenizer, max_length = 512):\n        self.texts = texts\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        label = self.labels[idx]\n\n        inputs = self.tokenizer(\n            text,\n            padding = 'max_length',\n            truncation = True,\n            max_length = self.max_length,\n            return_tensors = 'pt'\n        )\n\n        input_ids = inputs['input_ids'].squeeze(0)\n        attention_mask = inputs['attention_mask'].squeeze(0)\n\n        return {'input_ids' : input_ids, 'attention_mask' : attention_mask, \n                'label' : torch.tensor(label).float() }\n\n\nclass LabelClassifier(nn.Module):\n\n    def __init__(self, model):\n        super(LabelClassifier, self).__init__()\n        self.model = model\n        self.sentiment_output = nn.Linear(model.config.hidden_size , 2)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.model(input_ids = input_ids, attention_mask = attention_mask)\n        sentiment_logits = self.sentiment_output(outputs.last_hidden_state[:, 0, :])\n        sentiment_probs = torch.softmax(sentiment_logits, dim = -1)\n        return sentiment_probs\n\n\ntokenizer = ElectraTokenizer.from_pretrained('monologg/koelectra-base-v3-discriminator')\npretrained_model = ElectraModel.from_pretrained('monologg/koelectra-base-v3-discriminator')\nmodel = LabelClassifier(pretrained_model)\n\n\ntrain_dataset = SentimentDataset(train_texts, train_labels, tokenizer)\nval_dataset = SentimentDataset(val_texts, val_labels, tokenizer)\n\ntrain_loader = DataLoader(train_dataset, batch_size = 8 , shuffle = True)\nval_loader = DataLoader(val_dataset, batch_size = 8, shuffle = True)\n\n\ndevice = xm.xla_device()\n\nmodel.to(device)\n\noptimizer = AdamW(model.parameters(), lr = 2e-5)\nloss_fn_sentiment = nn.CrossEntropyLoss()\nepochs = 3\nprint(f\"Using device: {device}\")\n\n\n\nfor epoch in range(epochs):\n    model.train()\n    total_loss = 0\n\n    for batch in train_loader:\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['label'].long().to(device)\n\n        optimizer.zero_grad()\n\n        sentiment_probs = model(input_ids = input_ids, attention_mask = attention_mask)\n\n        loss = loss_fn_sentiment(sentiment_probs, labels)\n        loss.backward()\n\n        xm.optimizer_step(optimizer)\n        xm.mark_step()\n\n        total_loss += loss.item()\n\n    avg_train_loss = total_loss / len(train_loader)\n    print(f\"Epoch {epoch+1}/{epochs}, Average Training Loss: {avg_train_loss}\")\n\n\n    model.eval()\n    val_loss = 0\n    correct_labels = 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            sentiment_probs = model(input_ids = input_ids, attention_mask = attention_mask)\n            loss_sentiment = loss_fn_sentiment(sentiment_probs, labels)\n\n            val_loss += loss_sentiment.item()\n            preds_labels = torch.argmax(sentiment_probs, dim = 1)\n            correct_labels += (preds_labels == labels).sum().item()\n\n    avg_val_loss = val_loss / len(val_loader)\n    accuracy_labels = correct_labels / len(val_loader.dataset)\n    print(f\"Validation Loss: {avg_val_loss}, Accuracy (Sentiment): {accuracy_labels}\")\n\n\ndef calculate_metrics_with_threshold(model, val_loader, device, threshold=0.45):\n    model.eval()\n    tp, fn, tn, fp = 0, 0, 0, 0\n\n    with torch.no_grad():\n        for batch in val_loader:\n            # 데이터 로드\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            # 모델 예측\n            sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            # Threshold 적용\n            preds_labels = (sentiment_probs[:, 1] > threshold).long()  # Positive 클래스 확률 기준\n\n            # Recall 및 Specificity 계산\n            tp += ((preds_labels == 1) & (labels == 1)).sum().item()  # True Positives\n            fn += ((preds_labels == 0) & (labels == 1)).sum().item()  # False Negatives\n            tn += ((preds_labels == 0) & (labels == 0)).sum().item()  # True Negatives\n            fp += ((preds_labels == 1) & (labels == 0)).sum().item()  # False Positives\n\n    # Recall 계산\n    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n\n    # Specificity 계산\n    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0.0\n    accuracy = (tn + tp) / (tn + tp + fp + fn)\n    return recall, specificity, accuracy\nfor threshold in [0.6, 0.5, 0.4]:\n    recall, specificity, accuracy = calculate_metrics_with_threshold(model, val_loader, device, threshold=threshold)\n    print(f\"Threshold: {threshold:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, \\\n    Accuracy : {accuracy:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T06:53:23.385874Z","iopub.execute_input":"2025-01-09T06:53:23.386329Z","iopub.status.idle":"2025-01-09T06:59:12.306793Z","shell.execute_reply.started":"2025-01-09T06:53:23.386293Z","shell.execute_reply":"2025-01-09T06:59:12.305508Z"}},"outputs":[{"name":"stdout","text":"Using device: xla:0\nEpoch 1/3, Average Training Loss: 0.4756864235348945\nValidation Loss: 0.3805523668016706, Accuracy (Sentiment): 0.9416058394160584\nEpoch 2/3, Average Training Loss: 0.3497067285280158\nValidation Loss: 0.3811680836336953, Accuracy (Sentiment): 0.9416058394160584\nEpoch 3/3, Average Training Loss: 0.34342056904396\nValidation Loss: 0.37136587500572205, Accuracy (Sentiment): 0.9416058394160584\nThreshold: 0.9000, Recall: 0.8779, Specificity: 0.9860,     Accuracy : 0.9343\nThreshold: 0.8000, Recall: 0.8779, Specificity: 0.9860,     Accuracy : 0.9343\nThreshold: 0.7000, Recall: 0.8779, Specificity: 0.9860,     Accuracy : 0.9343\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"for threshold in [0.6, 0.5, 0.4]:\n    recall, specificity, accuracy = calculate_metrics_with_threshold(model, val_loader, device, threshold=threshold)\n    print(f\"Threshold: {threshold:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}, \\\n    Accuracy : {accuracy:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def find_misclassified_texts(model, val_loader, device, threshold=0.5):\n    model.eval()\n    misclassified_positive_as_negative = []  # 긍정을 부정으로 분류\n    misclassified_negative_as_positive = []  # 부정을 긍정으로 분류\n\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batch['input_ids'].to(device)\n            attention_mask = batch['attention_mask'].to(device)\n            labels = batch['label'].long().to(device)\n\n            sentiment_probs = model(input_ids=input_ids, attention_mask=attention_mask)\n\n            # Threshold 적용\n            preds_labels = (sentiment_probs[:, 1] > threshold).long()\n\n            # 원본 텍스트와 잘못 분류된 텍스트 확인\n            for i, (pred, label) in enumerate(zip(preds_labels, labels)):\n                original_text = tokenizer.decode(batch['input_ids'][i], skip_special_tokens=True)\n\n                # 긍정을 부정으로 잘못 분류\n                if label == 1 and pred == 0:\n                    misclassified_positive_as_negative.append(original_text)\n\n                # 부정을 긍정으로 잘못 분류\n                elif label == 0 and pred == 1:\n                    misclassified_negative_as_positive.append(original_text)\n\n    return misclassified_positive_as_negative, misclassified_negative_as_positive\n\n\n# 잘못 분류된 텍스트 확인\nmisclassified_positive_as_negative, misclassified_negative_as_positive = find_misclassified_texts(\n    model, val_loader, device, threshold=0.5\n)\n\n# 출력\nprint(\"긍정을 부정으로 분류한 텍스트:\")\nfor text in misclassified_positive_as_negative:\n    print(text)\n\nprint(\"\\n부정을 긍정으로 분류한 텍스트:\")\nfor text in misclassified_negative_as_positive:\n    print(text)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-09T07:03:46.244753Z","iopub.execute_input":"2025-01-09T07:03:46.245976Z","iopub.status.idle":"2025-01-09T07:04:57.899500Z","shell.execute_reply.started":"2025-01-09T07:03:46.245916Z","shell.execute_reply":"2025-01-09T07:04:57.898289Z"}},"outputs":[{"name":"stdout","text":"긍정을 부정으로 분류한 텍스트:\n가격이 많이 올랐네요 ~ ㅎ\n기승전 진라면 뭐 먹을까 고민하다 삼\n예전 저렴할때 생각하면 많이 올랐네요\n진라면은 제 입에는 안맞는거 같아요! 특유의 냄새가 있네요!\n할인하네요 두개사니\n소세지 맛이 바꼈네요? 전에는 짜기만 해서 데쳐먹었는데 생으로 먹어도 안짜고 너무 맛있어요\n양이 생각보다 꽤많아요\nㅎ\n불맛나는 비엔나 어차피 햄은 몸에 좋지 않으니 맛있는거라도 …\n매운걸 못먹는 아이가 이 라면만 먹어요\n항상 배송도 빠르고 제품 손상 된 거 없이 잘 와요!! 계란두 하나도 안깨져서 오네요 ㅎ\n가격이저렴해서 구입햇는데 육수대용으로 잘사용합니다\n아이가 매운걸 못먹어서 늘 순한맛만 사네요 근데 먹다보니 이것만한것도 없는듯 ㅋ\n아직 먹어보진 못했지만 도시락 반찬으로 샀어요\n\n부정을 긍정으로 분류한 텍스트:\n평많은곳에서 주문하세여 ~ 경험했다ㅋㅋ\n빠른 배송 감사합니다\n","output_type":"stream"}],"execution_count":22}]}